---
layout:     post
title:      RAG创始人关于RAG Agent的10个思考(上)
subtitle:
date:       2025-05-11
author:     Bruce Wong
header-img: img/IMG_1553.WEBP
catalog: true
tags:
    - Agile
    - 敏捷
    - 随笔
    - AI
---

现在AI应用落地常用的方式是RAG（Retrieval-Augmented Generation），即检索增强生成。和Agent结合更是让RAG的应用场景更为广泛。很多企业包括我自己都在尝试使用它来提高AI在企业中落地的效果。最近RAG的创始人Douwe Kiela 在LinkedIn上分享了他对RAG Agent在企业中的10个教训，对我自己也很有启发。今天结合他的视频内容和我自己的实践体会来分享一下。

## 1.更好的 LLM 不是（唯一）答案：
LLM 只是整个 AI 系统（特别是 RAG 系统，包括提取、检索、生成、联合优化）的一小部分（约 20%）。一个优秀的 RAG 系统配合普通的 LLM，效果可能优于一个顶尖 LLM 配合糟糕的 RAG 系统。关键是关注系统而非孤立的模型。
### 实践分享
我曾经参与优化过一个基于RAG的知识库问答系统。当时的情况是，团队做了测试，使用GPT-4的效果会好于GPT-3.5的效果，但是回答内容的准确率仍然低于50%。后来做了一些调整，准确率提升到80%以上：
- 提取企业数据到向量数据库之前，将数据格式化，例如都变成Markdown格式。同时清洗掉一些无效数据，例如HTML的标签等，页眉页脚、目录、引用等部分。
- 检索时候使用多路召回，不仅仅使用向量检索，还结合了关键词检索，联合重排后使用。这样可以提高召回率。
- 生成最终回复内容的时候，利用提示词工程来限定大模型使用的知识范围，例如只从召回的内容中生成回答，否则直接回答无法回复等方式，避免幻觉。
- 使用提示词工程例如：格式化指令、Few-Shot等来引导模型生成更好的内容。

在使用上述方法后，我们替换了GPT-3.5 Turbo，以及后续发布的成本更低的GPT-4o mini。虽然模型不是最新的最高级的版本，但是效果却是最好的。也就是Douwe Kiela所说的，RAG系统的整体效果比单一模型的效果更重要。

## 2.专业知识是你的燃料：
企业内部积累的专业知识和机构知识（通常存在于文档和数据中）是驱动 AI 产生价值的核心燃料。必须设法解锁这些专业知识。
### 实践分享
每个企业都有丰富的所在领域的领域知识，有一个项目是一个学校做一个AI私人教师，给每个学生提供个性化的学习方案。这个学校准备的RAG的数据，是他们自己的材料和特有的的教学方法，这也是他们和其他同行的主要区别，也是他们的行业壁垒。AI机器人基于这些数据的构建才会有能力解决这个领域的问题。而通用大模型是很难获得这么特殊的领域知识的。

## 3.企业规模是你的护城河：
企业的核心竞争力在于其独特的数据。真正的挑战在于大规模地利用这些数据，让 AI 能够处理大规模、甚至“嘈杂”的真实数据。成功做到这一点，就能构建竞争壁垒。
### 实践分享
我经历过的项目中，最开始确实有大量和复杂的数据清洗过程，为了给AI提供高质量的数据，提高RAG的召回率和质量。不过随着从试点到推广阶段，你会发现企业大量的数据都是带有“噪音”的。如果都要进行数据清洗，工作量和效率上都是不可能完成的任务。所以与其利用大量的时间做数据清洗，倒不如想办法让AI能够接受这些带有”噪音“的已存在的数据是更契合实际的。

## 4.试点与生产之间的鸿沟总是比预想的要大：
建立小规模试点相对容易（少量文档、用户、单一场景、低风险），但将其扩展到生产环境则面临巨大挑战（海量文档、大量用户、多场景、高安全风险、SLA 要求等）。
### 实践分享
还是企业内部知识库的AI项目，少量文档20～50个50K～100K大小文档的内容作为知识库的基础数据，召回率以及效率都很好。不过实际企业中的数据量和单文件大小都存在很大差异。铺开后先不考虑RAG的召回率和准确率。就说索引和召回的速度都成了问题。所以在试点阶段，需要考虑到后续的规模化的系统设计和应对方案，而不是只关注眼前的体量。但考虑多少需要基于实际项目来平衡。

## 5.速度比完美更重要：
不要追求一开始就完美。应尽早将（哪怕不完美的）系统交给真实用户使用，获取反馈并快速迭代。通过迭代“爬山”达到目标，而不是试图一次性设计出完美方案。
### 实践分享
这一点和第4点有冲突的感觉。如何把握快速且完美之间的平衡呢？还是分享几个实际项目中的情况：
- 找到企业最需要AI解决的问题，最好是单一问题，降低复杂度。快速实现，让客户看到效果。获得企业的认可。这个时候数据量不需要很大，主要是关注是是否能够让企业理解AI的价值。
- 按照生产环境的要求来设计系统，仍然是试点的单一问题，放大规模后，看看是否能够满足企业的要求。
例如我们在和一个小学合作研发AI私人教师的项目中，一开始是覆盖客户希望的全部学科中的三个，数学、语文、自然科学。但是提供资料是有限的的5M，同时参与验收体验的学生和老师总共20人。小规模验证需求可行性。这个过程用了1个月的时间。得到肯定效果后，通过扩充教材数据量，从5M到200M，参与的老师和学生扩充到300人。这个过程用了2个月的时间。期间有多次UAT来搜集反馈。这些都通过后，才开始进一步演进，例如模型的优化、数据优化、系统吞吐量的优化等。
所以保持快速交付与用户的参与是AI项目落地的关键。

**未完待续**

## 视频链接
[视频链接](https://www.bilibili.com/video/BV18yoVYzEVr/?spm_id_from=333.999.0.0&vd_source=2f1a3b4c8d7e5f6a9c3e4d5f6a7e8f9a)
<iframe src="//player.bilibili.com/player.html?isOutside=true&aid=114335183538805&bvid=BV18yoVYzEVr&cid=29407448928&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>